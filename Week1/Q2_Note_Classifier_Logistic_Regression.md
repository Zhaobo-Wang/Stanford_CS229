## <mark>激活函数 Sigmoid</mark>

激活函数在神经网络中扮演着至关重要的角色，其中 Sigmoid 激活函数是特别常用的一种，尤其在二分类问题中。Sigmoid 函数的数学表达式是：

![69cb53a9-352d-4957-8cc0-282c70f6e7ef](file:///D:/TypeDown_Screenshot/69cb53a9-352d-4957-8cc0-282c70f6e7ef.png)

其中 \( z \) 是输入信号的加权和（包括偏置），\( e \) 是自然对数的底数。以下是 Sigmoid 函数的几个主要作用：

### 1. 输出值的范围

<mark>Sigmoid 函数将任意实数值映射到 \( (0, 1) \) 区间内，这使得它非常适合处理需要输出概率的场景。例如，在二分类任务中，Sigmoid 的输出可以解释为属于某一类别的概率。</mark>

### 2. 平滑梯度

Sigmoid 函数是可微的，这意味着它在其定义域内处处有导数。<mark>这个特性是神经网络中使用梯度下降方法进行有效学习的关键。</mark> 函数的平滑性质确保了梯度下降能够通过小小的权重调整逐渐减少误差。

### 3. 非线性

虽然 Sigmoid 函数本身是一条曲线，但它引入了非线性。如果没有非线性，无论神经网络有多少层，最终都可以被简化为单一的线性模型，这限制了网络的表达能力。通过使用 Sigmoid 或其他非线性激活函数，神经网络能够学习并模拟复杂的关系。

### 4. 渐进性质

Sigmoid 函数两端渐进于 0 和 1，这有助于清晰地区分激活值对应的“开/关”状态，即很小的变化在输入端（特别是输入值较大或较小时）不会显著改变输出值，有助于模型的稳定性。

### 缺点

尽管 Sigmoid 函数非常有用，但它也有一些缺点，特别是在深度网络中：

- **梯度消失**：对于非常高或非常低的输入值，Sigmoid 函数的梯度几乎为零，这导致在梯度下降过程中，权重更新非常缓慢，或者几乎不更新，这称为梯度消失问题。
- **输出不以零为中心**：Sigmoid 函数的输出均为正值（介于 0 和 1 之间），这可能会影响后续层的学习过程，因为它们处理的输入不是零中心的。

因此，尽管 Sigmoid 在某些情况下（如输出概率或二分类的最后一层）非常适用，但在其他情况下可能会选择 ReLU 或其他非线性函数作为激活函数，以避免梯度消失的问题，并提高训练速度。



```python
# Sigmoid 激活函数
def sigmoid(z):
    s = 1 / (1 + np.exp(-z))
    return s
```



---------------------------------------------------

### <mark>正向传播和反向传播</mark>

正向传播和反向传播是神经网络和其他机器学习模型训练过程中的两个基本步骤，它们共同工作来优化模型的参数，以便模型能够更好地学习和预测数据。下面详细解释这两个过程的意义和作用：



```python
def propagate(w, b, X, Y):
    m = X.shape[1]
    A = sigmoid(np.dot(w.T, X) + b)  # 计算激活值
    cost = (-1 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))  # 计算成本

    # 反向传播，计算梯度
    dw = (1 / m) * np.dot(X, (A - Y).T)
    db = (1 / m) * np.sum(A - Y)
    grads = {"dw": dw, "db": db}
    
    return grads, cost
```

![b9d981e4-ac41-449e-a436-ce9059573751](file:///D:/TypeDown_Screenshot/b9d981e4-ac41-449e-a436-ce9059573751.png)

![427eaf5d-9a6e-429c-85c3-3a8eedbc70cf](file:///D:/TypeDown_Screenshot/427eaf5d-9a6e-429c-85c3-3a8eedbc70cf.png)

### 正向传播（Forward Propagation）

正向传播是模型学习过程中的第一步，它的主要任务是计算预测输出并评估模型性能。



1. **数据处理**：输入数据（特征）被送入模型。

2. **模型计算**：数据流通过模型的各层。在每一层，都会进行如权重与输入数据的线性组合加上偏差等计算。

3. **激活函数**：线性输出通过激活函数（如Sigmoid、ReLU等），转换为非线性，以帮助模型学习和表示复杂的模式。

4. **输出生成**：最终的输出是对输入数据的预测，例如在二分类问题中，输出是预测类别为1的概率。

5. **损失计算**：计算损失函数，通常是实际标签和预测标签之间的差异。这个损失表明了模型当前的性能，损失越低，表示模型的预测越准确。
   
   

正向传播的目的是使用当前的参数（权重和偏差）来评估模型的效果，即如何准确地预测实际输出。此过程是确定模型当前“学习状态”的关键。



### 反向传播（Backpropagation）

反向传播是正向传播之后进行的，目的是优化模型参数（权重和偏差），以减少预测误差。



1. **损失梯度**：首先计算损失函数关于输出层每个输出的梯度。

2. **梯度传播**：这些梯度然后被传回（反向传播）到网络的前面的层。对每一层，都会计算损失关于该层权重的梯度。

3. **参数更新**：使用这些梯度，按照一定的学习率调整模型的参数。这个过程是通过梯度下降或其他优化算法完成的，目的是通过最小化损失函数来改进模型的权重。

4. **迭代优化**：反复执行正向传播和反向传播，每次迭代更新模型参数，直到模型性能达到满意的水平或达到预设的迭代次数。
   
   

反向传播的核心是“学习”：通过系统地调整网络参数来减少预测误差。这是神经网络训练中至关重要的步骤，因为它直接关系到模型的最终性能。



总的来说，<mark>正向传播提供了模型当前性能的评估，而反向传播则基于这些信息来改进模型。</mark>这两个过程循环进行，直到模型达到足够的准确性或完成设定的训练周期。



-----------------------------------------------------------------

### 正向传播

想象一下你在玩一个猜数字的游戏，你需要根据一些提示来猜一个数。在机器学习模型（比如逻辑回归或神经网络）中，正向传播的过程就像是根据现有的规则（模型的参数）来做出猜测。

1. **输入数据**：就像游戏开始，你得到了一些线索。在机器学习中，这些线索就是我们的数据（比如图片、文本或其他信息）。

2. **处理数据**：你根据这些线索进行思考，尝试猜出正确的数字。在模型中，这个过程涉及到利用模型的当前权重（一种内部规则或参数）和偏差来处理输入的数据。

3. **激活函数**：这就像你用某种方法（比如算数运算）来处理这些线索，帮助你更接近正确答案。在模型中，激活函数（比如 Sigmoid）帮助模型决定每一步应该如何调整它的猜测。

4. **输出结果**：在游戏中，你最后会给出一个答案；在模型中，这就是预测结果，例如预测图片中是否有猫。

5. **评估结果**：游戏结束后，你会知道猜得对不对，模型也是通过计算损失（实际结果和预测之间的差距）来评估它的预测准确性。

### 反向传播

如果你猜错了，你可能会回想你的思考过程，看看哪里出了问题，并思考如何在下次游戏中改进。反向传播就是这样的过程，但是针对的是机器学习模型：

1. **计算误差**：就像回顾你的猜测一样，反向传播首先看看模型犯了什么错误（即损失函数）。

2. **找到责任**：然后，它会找出是哪些权重和偏差导致了错误，通过计算它们对错误的贡献来实现这一点。

3. **调整规则**：就像你决定下次如何改进你的猜测策略一样，模型会根据这些“责任”来调整它的权重和偏差，以减少未来的错误。

4. **重复尝试**：就像你不断玩游戏来完善你的策略一样，模型通过多次重复正向传播和反向传播的过程来不断学习和改进，直到它变得足够好。

简而言之，正向传播是模型做出预测的过程，而反向传播是模型从错误中学习并改进自己的过程。这两个过程共同帮助模型变得更加精确，就像你通过不断练习来提高玩游戏的技巧一样。

---------------------------------------------------------

## <mark>Predict 函数</mark>



`predict` 函数在机器学习模型中扮演了一个关键的角色，其主要作用是使用训练好的模型对新的或未见过的数据进行预测。这里是详细的解释：

### 主要功能

在逻辑回归模型（或任何分类模型）中，`predict` 函数的核心任务是根据输入的特征数据（X）使用训练后的参数（权重 w 和偏差 b）来预测输出标签（Y）。这通常涉及以下步骤：

1. **计算概率**：
   
   * 利用训练得到的权重（w）和偏差（b），通过模型（例如逻辑回归的 Sigmoid 函数）计算输入数据（X）对应的预测概率。这个过程通常是通过将数据矩阵与权重矩阵相乘，然后加上偏差，并将结果通过 Sigmoid 函数转换为概率输出。
   * 具体到逻辑回归，预测函数通过 σ(wTX+b) 计算每个实例属于正类的概率。

2. **决策阈值**：
   
   * 将计算得到的概率值与一个阈值（通常是0.5）进行比较，以决定最终的类别。如果概率大于0.5，预测结果为正类（通常编码为1）；如果概率小于或等于0.5，预测结果为负类（通常编码为0）。



### 应用

* **模型评估**：`predict` 函数常用于测试数据集，以评估模型的性能（如准确度、召回率、精确度等指标）。
* **实际应用**：在模型开发完成并通过验证后，`predict` 函数可以用于实际应用中，如在线预测、产品推荐、疾病诊断等领域。

总的来说，`predict` 函数是将机器学习模型的理论和训练转化为实际应用的关键桥梁，它使模型能够在实际环境中为特定任务提供决策支持。



```python
# 预测函数
def predict(w, b, X):
    m = X.shape[1]
    Y_prediction = np.zeros((1, m))
    w = w.reshape(X.shape[0], 1)
    A = sigmoid(np.dot(w.T, X) + b)
    for i in range(A.shape[1]):
        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0
    return Y_prediction
```


